{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_NN_colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "RHc2ceWcydSI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "6a0d6b0f-a1a3-4fbe-dfcf-ffb5025463fd"
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gpg: keybox '/tmp/tmpfxqpsqoc/pubring.gpg' created\n",
            "gpg: /tmp/tmpfxqpsqoc/trustdb.gpg: trustdb created\n",
            "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wOxEoBQJykly",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kq_bW42GzJwQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-fbxNS9Azgeh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c747c612-f090-4dac-fde0-ff4361f79f19"
      },
      "cell_type": "code",
      "source": [
        "#check that you are using GPU\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "XHT_jwKk0LEK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d975edc8-0ca5-4e8c-8d0e-93c1146db8ea"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab  drive\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4UYr9_Po0dK1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"drive/Colab\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C5c4bWvl0p-5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7fb829a9-cfe7-442a-ac62-de17ece68074"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MNIST_NN_colab.ipynb\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "j8L_fpuY0riK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1b4fe909-e040-4d36-a2ad-586440c79dd6"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MNIST_NN_colab.ipynb  test_MNIST.csv  train_MNIST.csv\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fqyVSan82s8T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "534d5a51-30f5-4512-c9e2-5d2eb2f96ff3"
      },
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/Colab\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KkopTlyT3fmE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "import pandas as pd\n",
        "import csv as csv\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WOqgFmRI6QDI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##manual download, then use pd\n",
        "test_mnist= pd.read_csv('test_MNIST.csv', sep=',')\n",
        "train_mnist = pd.read_csv('train_MNIST.csv', sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zY5zOQmE6SBY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# split train - test and convert to numpy arrays with .values\n",
        "X_train, y_train= train_mnist.iloc[:, 1:].values, train_mnist.iloc[:, 0].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YNdrq0fN6fJg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d2ad3087-f691-4ee1-a4f0-d3cb34310ffe"
      },
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42000, 784)\n",
            "(42000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Izzn4nPB6g_G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_train = 42000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fDUy7stsD6EE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***Data augmentation***\n",
        "\n",
        "see here: https://machinelearningmastery.com/image-augmentation-deep-learning-keras/\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "V2bdZ0hOMgMX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Create and configure your ImageDataGenerator\n",
        "datagen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,height_shift_range=0.08, zoom_range=0.08)\n",
        "#fit it on train data\n",
        "datagen.fit(train)\n",
        "X_batch, y_batch = datagen.flow(train, train, batch_size=32)\n",
        "fit_generator(datagen, samples_per_epoch=len(train), epochs=100)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HxC4NpRXHu3R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train keras model"
      ]
    },
    {
      "metadata": {
        "id": "NOUwp4GE6irv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "# we have to preprocess the data into the right shape\n",
        "X_train = X_train.reshape(n_train, 28, 28, 1).astype('float32')\n",
        "# normalize from [0, 255] to [0, 1]\n",
        "X_train /= 255\n",
        "# numbers 0-9, so ten classes\n",
        "n_classes = 10\n",
        "# convert integer labels into one-hot vectors\n",
        "y_train = to_categorical(y_train, n_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eDdTb7nl6kWj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lo3SA6m36nO6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# number of convolutional filters\n",
        "n_filters = 32\n",
        "# convolution filter size\n",
        "# i.e. we will use a n_conv x n_conv filter\n",
        "n_conv = 3\n",
        "# pooling window size\n",
        "# i.e. we will use a n_pool x n_pool pooling window\n",
        "n_pool = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BNBmtLA96o2b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Activation\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "\n",
        "model.add(Convolution2D(n_filters, kernel_size=(n_conv, n_conv),\n",
        "        # we have a 28x28 single channel (grayscale) image so the input shape should be (28, 28, 1)\n",
        "        input_shape=(28, 28, 1)))\n",
        "\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(n_filters, kernel_size=(n_conv, n_conv)))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# then we apply pooling to summarize the features\n",
        "# extracted thus far\n",
        "model.add(MaxPooling2D(pool_size=(n_pool, n_pool)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sDlvJoW76qvv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Dropout, Flatten, Dense\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# flatten the data for the 1D layers\n",
        "model.add(Flatten())\n",
        "\n",
        "# Dense(n_outputs)\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# the softmax output layer gives us a probablity for each class\n",
        "model.add(Dense(n_classes))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9zuRya6t6vJA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TmoUmkIq6v6r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1714
        },
        "outputId": "9cbc4836-f5e3-4408-f0d6-18b23d8bc8b8"
      },
      "cell_type": "code",
      "source": [
        "# how many examples to look at during each update step\n",
        "batch_size = 1300\n",
        "\n",
        "# how many times to run through the full set of examples\n",
        "n_epochs = 50\n",
        "\n",
        "# the training may be slow depending on your computer\n",
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=n_epochs)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "42000/42000 [==============================] - 4s 84us/step - loss: 0.0707 - acc: 0.9784\n",
            "Epoch 2/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0639 - acc: 0.9802\n",
            "Epoch 3/50\n",
            "42000/42000 [==============================] - 3s 69us/step - loss: 0.0546 - acc: 0.9839\n",
            "Epoch 4/50\n",
            "42000/42000 [==============================] - 3s 69us/step - loss: 0.0514 - acc: 0.9839\n",
            "Epoch 5/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0478 - acc: 0.9845\n",
            "Epoch 6/50\n",
            "42000/42000 [==============================] - 3s 71us/step - loss: 0.0433 - acc: 0.9865\n",
            "Epoch 7/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0413 - acc: 0.9877\n",
            "Epoch 8/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0380 - acc: 0.9882\n",
            "Epoch 9/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0365 - acc: 0.9879\n",
            "Epoch 10/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0333 - acc: 0.9895\n",
            "Epoch 11/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0322 - acc: 0.9894\n",
            "Epoch 12/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0300 - acc: 0.9904\n",
            "Epoch 13/50\n",
            "42000/42000 [==============================] - 3s 71us/step - loss: 0.0308 - acc: 0.9902\n",
            "Epoch 14/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0260 - acc: 0.9911\n",
            "Epoch 15/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0275 - acc: 0.9912\n",
            "Epoch 16/50\n",
            "42000/42000 [==============================] - 3s 69us/step - loss: 0.0250 - acc: 0.9918\n",
            "Epoch 17/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0256 - acc: 0.9918\n",
            "Epoch 18/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0230 - acc: 0.9923\n",
            "Epoch 19/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0212 - acc: 0.9925\n",
            "Epoch 20/50\n",
            "42000/42000 [==============================] - 3s 71us/step - loss: 0.0230 - acc: 0.9923\n",
            "Epoch 21/50\n",
            "42000/42000 [==============================] - 3s 69us/step - loss: 0.0208 - acc: 0.9931\n",
            "Epoch 22/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0193 - acc: 0.9935\n",
            "Epoch 23/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0192 - acc: 0.9932\n",
            "Epoch 24/50\n",
            "42000/42000 [==============================] - 3s 69us/step - loss: 0.0185 - acc: 0.9945\n",
            "Epoch 25/50\n",
            "42000/42000 [==============================] - 3s 69us/step - loss: 0.0181 - acc: 0.9940\n",
            "Epoch 26/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0184 - acc: 0.9944\n",
            "Epoch 27/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0183 - acc: 0.9937\n",
            "Epoch 28/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0175 - acc: 0.9941\n",
            "Epoch 29/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0164 - acc: 0.9945\n",
            "Epoch 30/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0162 - acc: 0.9946\n",
            "Epoch 31/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0183 - acc: 0.9939\n",
            "Epoch 32/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0177 - acc: 0.9939\n",
            "Epoch 33/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0149 - acc: 0.9949\n",
            "Epoch 34/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0141 - acc: 0.9951\n",
            "Epoch 35/50\n",
            "42000/42000 [==============================] - 3s 69us/step - loss: 0.0139 - acc: 0.9954\n",
            "Epoch 36/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0133 - acc: 0.9959\n",
            "Epoch 37/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0127 - acc: 0.9958\n",
            "Epoch 38/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0137 - acc: 0.9955\n",
            "Epoch 39/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0135 - acc: 0.9957\n",
            "Epoch 40/50\n",
            "42000/42000 [==============================] - 3s 71us/step - loss: 0.0130 - acc: 0.9954\n",
            "Epoch 41/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0137 - acc: 0.9953\n",
            "Epoch 42/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0129 - acc: 0.9955\n",
            "Epoch 43/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0125 - acc: 0.9955\n",
            "Epoch 44/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0113 - acc: 0.9961\n",
            "Epoch 45/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0115 - acc: 0.9961\n",
            "Epoch 46/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0111 - acc: 0.9964\n",
            "Epoch 47/50\n",
            "42000/42000 [==============================] - 3s 71us/step - loss: 0.0127 - acc: 0.9955\n",
            "Epoch 48/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0131 - acc: 0.9956\n",
            "Epoch 49/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0119 - acc: 0.9964\n",
            "Epoch 50/50\n",
            "42000/42000 [==============================] - 3s 70us/step - loss: 0.0107 - acc: 0.9965\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f491c73a588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "metadata": {
        "id": "MuaLNnB26v9S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "0ae97a35-470d-4a5b-98f0-4f7e8a7d590d"
      },
      "cell_type": "code",
      "source": [
        "X_test = test_mnist.values.astype('float32')\n",
        "X_test"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "TGEVty6V9ONE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0366f20-d5e6-4bd0-df70-d53dd2a9a0e2"
      },
      "cell_type": "code",
      "source": [
        "print(X_test.shape)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1Yr6Z_hi9nrM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_test= 28000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F3wrOpBo8S7Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#reshape X_test as I did for X_train before\n",
        "X_test = X_test.reshape(n_test, 28, 28, 1)\n",
        "# normalize from [0, 255] to [0, 1]\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OBeESUIv9w30",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c52987af-8a77-41eb-eac8-cabb76e01615"
      },
      "cell_type": "code",
      "source": [
        "#now finally both test and train have the same dimension\n",
        "print(X_test.shape)\n",
        "print(X_train.shape)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28000, 28, 28, 1)\n",
            "(42000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a0UHaNQN610i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4be7fe57-168a-46ab-d86c-23e2a539e01e"
      },
      "cell_type": "code",
      "source": [
        "# prediction\n",
        "yPred = model.predict_classes(X_test,verbose=1)\n",
        "#convert to integer\n",
        "yPred = yPred.astype(int)\n",
        "#create a series with the predictions\n",
        "results = pd.Series(yPred,name=\"Label\")\n",
        "# then a second series with the index from 1 to x\n",
        "index= pd.Series(range(1,28001), name = \"ImageId\")\n",
        "#join the two series into a single dataframe\n",
        "submission = pd.concat([index, results], axis = 1)\n",
        "#save results to csv\n",
        "submission.to_csv(\"CNN_mnist3.csv\",index=False)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28000/28000 [==============================] - 3s 103us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R0UESzGD7y1_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DJhn2R-yJLAs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "other usefu resource\n",
        "https://yashk2810.github.io/Applying-Convolutional-Neural-Network-on-the-MNIST-dataset/"
      ]
    },
    {
      "metadata": {
        "id": "5CiOyW7kJNKg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}