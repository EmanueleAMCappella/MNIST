{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used [this resource](https://nextjournal.com/schmudde/ml4a-mnist) to learn Convolutional Neural Network on the MNIST challenge "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try google [Colab](https://colab.research.google.com/notebooks/welcome.ipynb#recent=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EAMC\n",
      "C:\\Users\\EAMC\\Desktop\\Book_ML_deepL\n"
     ]
    }
   ],
   "source": [
    "#This is the Kaggle challenge\n",
    "#check current directory\n",
    "%cd\n",
    "#change working directory where the file is\n",
    "%cd ~\\Desktop\\Book_ML_deepL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import csv as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##manual download, then use pd\n",
    "test_mnist= pd.read_csv('test_MNIST.csv', sep=',')\n",
    "train_mnist = pd.read_csv('train_MNIST.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 13s 1us/step\n"
     ]
    }
   ],
   "source": [
    "#from keras.datasets import mnist\n",
    "#(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train - test and convert to numpy arrays with .values\n",
    "X_train, y_train= train_mnist.iloc[:, 1:].values, train_mnist.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784)\n",
      "(42000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 42000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "# we have to preprocess the data into the right shape\n",
    "X_train = X_train.reshape(n_train, 28, 28, 1).astype('float32')\n",
    "# normalize from [0, 255] to [0, 1]\n",
    "X_train /= 255\n",
    "# numbers 0-9, so ten classes\n",
    "n_classes = 10\n",
    "# convert integer labels into one-hot vectors\n",
    "y_train = to_categorical(y_train, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of convolutional filters\n",
    "n_filters = 32\n",
    "# convolution filter size\n",
    "# i.e. we will use a n_conv x n_conv filter\n",
    "n_conv = 3\n",
    "# pooling window size\n",
    "# i.e. we will use a n_pool x n_pool pooling window\n",
    "n_pool = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "\n",
    "model.add(Convolution2D(n_filters, kernel_size=(n_conv, n_conv),\n",
    "        # we have a 28x28 single channel (grayscale) image so the input shape should be (28, 28, 1)\n",
    "        input_shape=(28, 28, 1)))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(n_filters, kernel_size=(n_conv, n_conv)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# then we apply pooling to summarize the features\n",
    "# extracted thus far\n",
    "model.add(MaxPooling2D(pool_size=(n_pool, n_pool)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout, Flatten, Dense\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# flatten the data for the 1D layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dense(n_outputs)\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# the softmax output layer gives us a probablity for each class\n",
    "model.add(Dense(n_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many examples to look at during each update step\n",
    "batch_size = 128\n",
    "\n",
    "# how many times to run through the full set of examples\n",
    "n_epochs = 5\n",
    "\n",
    "# the training may be slow depending on your computer\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see [here](https://www.kaggle.com/snbhanja/mnist-keras)\n",
    "and [here](https://hackernoon.com/keras-with-gpu-on-amazon-ec2-a-step-by-step-instruction-4f90364e49ac)\n",
    "\n",
    "and [here](http://liufuyang.github.io/2017/04/02/just-another-tensorflow-beginner-guide-4.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_mnist.values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "yPred = model.predict_classes(X_test,verbose=1)\n",
    "#convert to integer\n",
    "yPred = yPred.astype(int)\n",
    "#create a series with the predictions\n",
    "results = pd.Series(yPred,name=\"Label\")\n",
    "# then a second series with the index from 1 to x\n",
    "index= pd.Series(range(1,28001), name = \"ImageId\")\n",
    "#join the two series into a single dataframe\n",
    "submission = pd.concat([index, results], axis = 1)\n",
    "#save results to csv\n",
    "submission.to_csv(\"CNN_mnist.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
